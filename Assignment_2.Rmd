---
documentclass: article
fontsize: 10pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    fig_caption: yes
    toc: false
    latex_engine: xelatex
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}

update.packages("rlang")
library(xfun)
library(class)#for the knn.cv function
library(tidyverse)
library(rprojroot)
library(kableExtra)
library(MASS)#lda function
library(biotools)
library(ISLR2)
library(patchwork)
library(randomForest) 
library(viridis)
library(GPArotation)
library(psych) #EFA
library(maptools)
library(lavaan)
library(HDclassif)
library(mclust)
library(fdm2id)

# this package does not work for the newest version of R --> 
# only load if the local data files are not there
if (!file.exists(find_root_file("data/rect_constr.csv", 
     criterion = has_file("MultivariateStatistics_assignment.Rproj")))) {
  library(smacof)
} 
 
knitr::opts_chunk$set(echo = TRUE)
```

# Task 1

All R scripts and the data can be found on [this GitHub repository](https://github.com/raiisac/MultivariateStatistics_assignment).
```{r load, include=FALSE, message=FALSE, warning=FALSE}
#load the data and functions
data(College)

#test the difference between centroids
Wilks_manova <- function(data, group = "Private"){
  lm.out <- lm(cbind(
    sapply(X = colnames(data)[colnames(data) != group], 
           FUN = function(x) get(x)))~ 
       get((group)), 
   data = data)
  s <- summary(manova(lm.out), test = c("Wilks"))
  return(s$stats[1, "Pr(>F)"])#return the pvalue
}
#test the differences in var-cov matrix between groups
boxM_test <- function(data, group = "Private"){
  out <- boxM(data[,colnames(data) != group], data[,group])
  return(out$p.value)#return the pvalue
}

#execute lda with LOOCV and save the hit rate, sensitivity, and specificity
lda_analysis <- function(data, group = "Private", datatype){
  K <- length(unique(levels(data[,group])))
  positivelevel <- levels(data[,group])[K]# by default, it is assumed the last level is the positive level
  negativelevel <-  levels(data[,group])[-K]
  lda.out <- lda(
    formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
    data = data,
    prior = rep(1/K, K),
    CV = TRUE)
  tab <- table(data[,group], lda.out$class)
  out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "LDA"
  )
  return(out)
}
#execute qda with LOOCV and save the hit rate, sensitivity, and specificity
qda_analysis <- function(data, group = "Private", datatype){
  K <- length(unique(levels(data[,group])))
  positivelevel <- levels(data[,group])[K]# by default, it is assumed the last level is the positive level
  negativelevel <-  levels(data[,group])[-K]
  qda.out <- qda(
    formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
    data = data,
    prior = rep(1/K, K),
    CV = TRUE)
  tab <- table(data[,group], qda.out$class)
  out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "QDA"
  )
  return(out)
}

knn_analysis <-  function(data, group = "Private", datatype, testk){
  #In this function, we test a knn approach with several different values of K and we choose the one with the highest hit rate. If there are ties for the best hit rate, we choose the lowest K
  #testk is a vector for all values of K that should be tried.
  K <- length(unique(levels(data[,group])))
  positivelevel <- levels(data[,group])[K]# by default, it is assumed the last level is the positive level
  negativelevel <-  levels(data[,group])[-K]
  output <- data.frame(hitrate = NA,
                    sensitivity = NA,
                    specificity = NA,
                    data = datatype,
                    method = "KNN",
                    K = testk)
  for (x in testk) {
    knn.out <- knn.cv(train = data[,colnames(data) != group],
                      cl = data[, group],
                      k = x,
                      prob = TRUE
                      )
    tab <- table(data[,group], unname(knn.out))
    out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "KNN",
                    K = x
    )
  output[x, ] <- out
  }
  graph <- output %>%
    pivot_longer(cols = c("hitrate","sensitivity", "specificity"),
                 names_to = "performance.measure", values_to = "value") %>%
    ggplot() +
    geom_line(aes(color = `performance.measure`, x = K, y = value)) +
    ylab("Performance") + theme_bw() + ylim(0.6, 1)
  selected <- which(output$hitrate == max(output$hitrate))[1]
  return(list(graph,output[selected,]))
}

bagging_analysis <- function(data, group = "Private", datatype, ntree){
  K <- length(unique(levels(data[,group])))
  positivelevel <- levels(data[,group])[K]# by default, it is assumed the last level is the positive level
  negativelevel <-  levels(data[,group])[-K]
  nvar <- ncol(data)-1
  bagging.out <- randomForest(
    formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
    data = data,
    mtry = nvar,
    ntree = ntree,
    importance = TRUE)
  tab <- table(data[,group], bagging.out$predicted) #the predicted values of the input data based on out-of-bag samples.
  out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "bagging"
    )
  graph <- bagging.out$importance %>% 
    as.data.frame %>%
    dplyr::select(MeanDecreaseGini) %>%
    mutate(Var = rownames( bagging.out$importance )) %>%
    ggplot() + geom_point(aes(x=MeanDecreaseGini, y=Var)) + 
  scale_y_discrete(limits = names(sort(bagging.out$importance[,4]))) +
    theme_bw() + ylab("")
  return(list(graph, out))
}

RF_analysis <- function(data, group = "Private", datatype, ntree, mtry){
  K <- length(unique(levels(data[,group])))
  nvar <- ncol(data)-1
  positivelevel <- levels(data[,group])[K]# by default, it is assumed the last level is the positive level
  negativelevel <-  levels(data[,group])[-K]
  if (mtry != "optimize") {
    bagging.out <- randomForest(
      formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
      data = data,
      mtry = mtry,
      ntree = ntree,
      importance = TRUE)
    tab <- table(data[,group], bagging.out$predicted) #the predicted values of the input data based on out-of-bag samples.
    out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "randomForest"
      )
    graph <- bagging.out$importance %>% 
      as.data.frame %>%
      dplyr::select(MeanDecreaseGini) %>%
      mutate(Var = rownames( bagging.out$importance )) %>%
      ggplot() + geom_point(aes(x=MeanDecreaseGini, y=Var)) + 
    scale_y_discrete(limits = names(sort(bagging.out$importance[,4]))) +
      theme_bw() + ylab("")
    return(list(graph, out))
  
  }else{
    output <- data.frame(hitrate = NA,
                    sensitivity = NA,
                    specificity = NA,
                    data = datatype,
                    method = "randomForest",
                    mtry = 1:nvar)
    for (mtry in 1:nvar) {
    bagging.out <- randomForest(
      formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
      data = data,
      mtry = mtry,
      ntree = ntree,
      importance = TRUE)
    tab <- table(data[,group], bagging.out$predicted) #the predicted values of the input data based on out-of-bag samples.
    out <- data.frame(hitrate = sum(diag(tab))/sum(tab),
                    sensitivity = tab[positivelevel, positivelevel] /
                      sum(tab[positivelevel,]),
                    specificity = tab[negativelevel, negativelevel] /
                      sum(tab[negativelevel,]),
                    data = datatype,
                    method = "randomForest",
                    mtry = mtry
      )
  output[mtry, ] <- out
  }
  graphopt <- output %>%
    pivot_longer(cols = c("hitrate","sensitivity", "specificity"),
                 names_to = "performance.measure", values_to = "value") %>%
    ggplot() +
    geom_line(aes(color = `performance.measure`, x = mtry, y = value)) +
    ylab("Performance") + theme_bw() + ylim(0.6, 1)
  selected <- which(output$hitrate == max(output$hitrate))[1]
  bagging.out <- randomForest(
      formula(paste0(group, "~", paste(colnames(data)[colnames(data) != group], 
                                     collapse = "+"))),
      data = data,
      mtry = output[selected,'mtry'],
      ntree = ntree,
      importance = TRUE)
  graph <- bagging.out$importance %>% 
      as.data.frame %>%
      dplyr::select(MeanDecreaseGini) %>%
      mutate(Var = rownames( bagging.out$importance )) %>%
      ggplot() + geom_point(aes(x=MeanDecreaseGini, y=Var)) + 
    scale_y_discrete(limits = names(sort(bagging.out$importance[,4]))) +
      theme_bw() + ylab("")
  return(list(graph, output[selected, ], graphopt))
  }
}
```

The data consists of `r ncol(College)` variables of which the categorical variable *Private* denotes whether the school is private (*Private == Yes*) or not (*Private == No*). There are `r nrow(College)` schools in the data; `r sum(College$Private == "Yes")` (`r round(sum(College$Private == "Yes")/nrow(College)*100,2)`%) private schools and `r sum(College$Private == "No")` (`r round(sum(College$Private == "No")/nrow(College)*100,2)`%) non-private schools.

Before we start to build models to distinguish private and non-private schools, Wilk's lambda test is performed where the null hypothesis states that the centroid (mean) in both groups is the same. Both in the log-transformed and the original (centered or standardized) data, this null hypothesis is rejected. This means that the centroids of private and non-private schools differ significantly. 

The test of Box to test for equality of within-group covariance matrices shows that $H_0$ of equal covariance matrices across groups is not supported by the data. However, we still report on the results from LDA (which assumes equal covariances) since the alternative, QDA, does not always perform better because lower bias of the QDA classifier may not outweigh its higher model complexity.

Table \@ref(tab:compareresults) shows all results for the different performance measures (hit rate, sensitivity and specificity) and the different datasets. overall, sensitivity (proportion of positive observations that are being correctly classified) tends to be higher than specificity (proportion of negative observations that are being correctly classified) meaning it's generally easier to detect Private schools than non-private schools.

As expected it doesn't matter whether the data is standardized or centered for the QDA and LDA models and log-transforming skewed variables yields a higher hit rate in LDA and QDA. The hit rate is higher in LDA than in QDA which suggests that the true decision boundary is likely close to linear. The extra complexity of QDA is not worthwhile.

It is curious that KNN works so badly on the centered data with log-transformed skewed variables. 
The highest overall hit rate, for all datasets, is achieved in the random forest models. Bagging achieves approximately the same performance as LDA although it sacrifices specificity for higher sensitivity.


```{r classification, include=TRUE, echo = TRUE, message=FALSE, warning=FALSE, cache = TRUE}
College_logtranfskewed <- College %>%
  mutate(Apps = log(Apps),
         Accept = log(Accept),
         Enroll = log(Enroll),
         Top10perc = log(Top10perc),
         F.Undergrad = log(F.Undergrad),
         P.Undergrad = log(P.Undergrad),
         Books = log(Books),
         Personal = log(Personal),
         Expend = log(Expend))
College_centered <- College %>% 
  dplyr::select(-Private) %>% 
  scale(center = TRUE, scale = FALSE) %>%
  as.data.frame() %>%
  mutate(Private = College$Private)
College_logtranfskewed_centered <- College_logtranfskewed %>% 
  dplyr::select(-Private) %>%  
  scale(center = TRUE, scale = FALSE) %>%
  as.data.frame() %>%
  mutate(Private = College$Private)
College_std <- College %>% 
  dplyr::select(-Private) %>%  
  scale(center = TRUE, scale = TRUE) %>%
  as.data.frame() %>%
  mutate(Private = College$Private)
College_logtranfskewed_std <- College_logtranfskewed %>% 
  dplyr::select(-Private) %>%  
  scale(center = TRUE, scale = TRUE) %>%
  as.data.frame() %>%
  mutate(Private = College$Private)
testlist <- list(center = College_centered,
                 center_logtransfskewed = College_logtranfskewed_centered,
                 std = College_std,
                 std_logtransfskewed = College_logtranfskewed_std
                 )

#test the difference between centroids
wilks_results <- testlist %>% map(function(x) Wilks_manova(x, "Private"))
#In each dataset, H0:mu_{yes} = mu_{no} is rejected --> 
# centroids of Private and non-private schools differ significantly

#test the difference between centroids
boxm_results <- testlist %>% map(function(x) boxM_test(x, "Private"))

#LDA
lda_results <- map2(testlist, names(testlist), 
                    function(x,y){lda_analysis(x,"Private", y)}) %>%
  do.call("rbind", .)
  
#QDA
qda_results <- map2(testlist, names(testlist), 
                    function(x,y){qda_analysis(x,"Private", y)}) %>%
  do.call("rbind", .)
  
#KNN
knn_output <- map2(testlist, names(testlist), 
                    function(x,y){knn_analysis(x,"Private", y, 1:100)})
knn_results <- lapply(knn_output, function(element){
  element[[2]] # The first element contains graphs
})
knn_results <- knn_results %>%
  do.call("rbind", .)

#bagging
bagging_output <- map2(testlist, names(testlist), 
                    function(x,y){bagging_analysis(x, "Private", y, 
                                              ntree = 2000)})
bagging_results <- lapply(bagging_output, function(element){
  element[[2]] # The first element contains graphs
})
bagging_results <- bagging_results %>%
  do.call("rbind", .)

#random forests
rf_output <- map2(testlist, names(testlist), 
                    function(x,y){RF_analysis(x, "Private", y, 
                                              ntree = 2000, mtry = "optimize")})
rf_results <- lapply(rf_output, function(element){
  element[[2]] # The first element contains graphs
})
rf_results <- rf_results %>%
  do.call("rbind", .)
```

```{r compareresults, echo=FALSE, message=FALSE, warning=FALSE}
as.data.frame(lda_results) %>% 
  bind_rows(as.data.frame(qda_results)) %>%
  bind_rows(as.data.frame(knn_results)) %>%
  bind_rows(as.data.frame(bagging_results)) %>%
  bind_rows(as.data.frame(rf_results)) %>%
  dplyr::select(-K, -mtry) %>%
  pivot_wider(names_from = data, 
              values_from = c(hitrate, sensitivity, specificity)) -> A
A %>% knitr::kable(
  caption = 'A performance comparison of the different methods',
  digits = 3,
  col.names = c("Method",rep(c("Centered", "Centered Logtransf",
                   "Standardized", "Standardized Logtransf"), 3)),
  booktabs = TRUE, 
  valign = 't'
) %>%
  row_spec(0, angle = 90) %>% 
  add_header_above(c(" ", "Hit rate" = 4, "Sensitivity" = 4, "Specificity" = 4)) %>%
  column_spec(2, color = "white", 
              background = spec_color(unlist(A[,2]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(3, color = "white", 
              background = spec_color(unlist(A[,3]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(4, color = "white", 
              background = spec_color(unlist(A[,4]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(5, color = "white", 
              background = spec_color(unlist(A[,5]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(6, color = "white", 
              background = spec_color(unlist(A[,6]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(7, color = "white", 
              background = spec_color(unlist(A[,7]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(8, color = "white", 
              background = spec_color(unlist(A[,8]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(9, color = "white", 
              background = spec_color(unlist(A[,9]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(10, color = "white", 
              background = spec_color(unlist(A[,10]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(11, color = "white", 
              background = spec_color(unlist(A[,11]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(12, color = "white", 
              background = spec_color(unlist(A[,12]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) %>%
  column_spec(13, color = "white", 
              background = spec_color(unlist(A[,13]), option = "viridis", 
                                      direction = -1, 
                                      scale_from = c(min(A[,2:13]), 
                                                     max(A[,2:13])))) 
```



For the K-nearest neighbour (KNN) approach, the function knn_cv from the *class* package is used to execute KNN with LOOCV and test values of K between 1 and 100. The model with the highest hit rate is chosen as the final model in Table \@ref(tab:compareresults). If there are multiple models with the same hit rate, the smallest K is chosen, Figure \@ref(fig:KNNgraphs) shows the results in each of the datasets. The chosen K is `r knn_results[1,'K']` for the centered data, `r knn_results[2,'K']` for the centered data where the skewed variables are log-transformed, `r knn_results[3,'K']` for the standardized data, `r knn_results[4,'K']` for the standardized data where the skewed variables are log-transformed.

```{r KNNgraphs, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, fig.width = 8, fig.height=5, fig.cap="Evolution of hit rate, sensitivity and specificity for different K in the KNN approach. A shows the centered data, B the centered data with log-transformed skewed variables, C shows the standardized data, and D the standardized data with log-transformed skewed variables."}
knn_graphs <- lapply(knn_output, function(element){
  element[[1]] # The first element contains graphs
  })
knn_graphs[[1]] + knn_graphs[[2]] + knn_graphs[[3]] + knn_graphs[[4]] +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = "collect")
```

For the bagging and  Random forest (RF) approach, the function randomForest from the *randomForest* package is used. 2000 bootstrapped data and trees are drawn in all models.  Figure \@ref(fig:bagginggraphs) and \@ref(fig:rfgraphs) show the importance of different variables in the final models. *F.Undergrad* and *outstate* are the most important one in all bagging and RF models. The difference in MeanDecreseGini (the mean decrease in the Gini index) between the most important variables (*F.Undergrad* and *Outstate*) and the other variables is much larger in the bagging model than in the RF models. *Enroll*, which is not at all important in the bagging models, is consistently the third most important variable in the RF models. 

For the RF results, we try different values for the mtry parameter which is the number of variables randomly sampled as candidates at each split. The model with the highest hit rate is chosen as the final model in Table \@ref(tab:compareresults). If there are multiple models with the same hit rate, the smallest mtry is chosen, Figure \@ref(fig:rfgraphsopt) shows the results in each of the datasets. The chosen value for mtry is `r rf_results[1,'mtry']` for the centered data (\@ref(fig:rfgraphsopt)A), `r rf_results[2,'mtry']` for the centered data where the skewed variables are log-transformed (\@ref(fig:rfgraphsopt)B), `r rf_results[3,'mtry']` for the standardized data (\@ref(fig:rfgraphsopt)C), `r rf_results[4,'mtry']` for the standardized data where the skewed variables are log-transformed (\@ref(fig:rfgraphsopt)D).

```{r bagginggraphs, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, fig.width = 8, fig.height=5, fig.cap="Variance importance plots for the bagging models. A shows the centered data, B the centered data with log-transformed skewed variables, C shows the standardized data, and D the standardized data with log-transformed skewed variables."}
bagging_graphs <- lapply(bagging_output, function(element){
  element[[1]] # The first element contains graphs
  })
bagging_graphs[[1]] + bagging_graphs[[2]] + bagging_graphs[[3]] + bagging_graphs[[4]] +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = "collect")
```

```{r rfgraphs, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, fig.width = 8, fig.height=5, fig.cap="Variance importance plots for the random forest models. A shows the centered data, B the centered data with log-transformed skewed variables, C shows the standardized data, and D the standardized data with log-transformed skewed variables."}
rf_graphs <- lapply(rf_output, function(element){
  element[[1]] # The first element contains graphs
  })
rf_graphs[[1]] + rf_graphs[[2]] + rf_graphs[[3]] + rf_graphs[[4]] +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = "collect")
```

```{r rfgraphsopt, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, fig.width = 8, fig.height=5, fig.cap="Optimization of the mtry parameter for the random forest models. A shows the centered data, B the centered data with log-transformed skewed variables, C shows the standardized data, and D the standardized data with log-transformed skewed variables."}
rf_graphs <- lapply(rf_output, function(element){
  element[[3]] # The first element contains graphs
  })
rf_graphs[[1]] + rf_graphs[[2]] + rf_graphs[[3]] + rf_graphs[[4]] +
  plot_annotation(tag_levels = 'A') +
  plot_layout(guides = "collect")
```

# Task 2

```{r load2, include=FALSE, message=FALSE, warning=FALSE}
load(find_root_file("data/fashion.Rdata", 
     criterion = has_file("MultivariateStatistics_assignment.Rproj")))
     
#centered variables
zshopping<-scale(train.data,center=TRUE,scale=FALSE)

##### HDclassif ######
set.seed(20)

#common dimension hddc() models "AkjBkQkD" and "AkjBQkD" with com_dim=2,3,4,5, or 6 fitted on the training data. 
names<-list()
ari_values<-list()
for(model in c("AkjBkQkD", "AkjBQkD")){
  for(dim in 2:5)
  {
    hddc.out<-hddc(zshopping,K=3,model=model,com_dim=dim, d_select="BIC",init="kmeans")
    ari<-adjustedRandIndex(hddc.out$class, train.target)
    model_name = paste(model,"_",toString(dim), sep="")
    names <-append(names, model_name)
    ari_values <-append(ari_values, ari)
    print(names)
    print(ari_values)
  }
}

#compare models
do.call(rbind, Map(data.frame, A=names, B=ari_values))

###### mclust model ######
set.seed(201)

#Mclust() models "VVE","VEV","EVV","VVV" fitted on the first 2,3,4,5, or 6 unstandardized principal components extracted from the training data. 
prcomp.out<-prcomp(zshopping)
#plot(prcomp.out$sd^2)
#cumsum(prcomp.out$sd^2/sum(prcomp.out$sd^2)) 
comp<-zshopping%*%prcomp.out$rotation 

names2<-list()
ari_values2<-list()
for(model in c("VVE","VEV","EVV","VVV")){
  for(c in 2:6)
  {
    mclust.out<-Mclust(comp[,1:c],G=3,modelNames=model) 
    ari<-adjustedRandIndex(mclust.out$class,train.target)
    model_name = paste(model,"_",toString(c), sep="")
    names2 <-append(names2, model_name)
    ari_values2 <-append(ari_values2, ari)
    print(names2)
    print(ari_values2)
  }
}

do.call(rbind, Map(data.frame, A=names2, B=ari_values2))

###### the best model (highest ARI value) selected is AkjBQkD_4 ######

hddc.out<-hddc(zshopping,K=3,model="AkjBQkD",com_dim=4, d_select="BIC",init="kmeans")
ari<-adjustedRandIndex(hddc.out$class, train.target)

#compute principal components
#prcomp.out<-prcomp(zshopping)
loading<-prcomp.out$rotation%*%diag(prcomp.out$sd)
#print loadings first two components
round(loading[,1:2],2)
Z<-predict(prcomp.out,zshopping)

#plot hddc solution in the space of the first two principal components
plot(Z,xlab="PC1",ylab="PC2",main="HDDC")
points(Z[hddc.out$class==1,],col="red")
points(Z[hddc.out$class==2,],col="blue")
points(Z[hddc.out$class==3,],col="green")

```

# Task 3
```{r load3, include=FALSE, message=FALSE, warning=FALSE}
if (file.exists(find_root_file("data/rect_constr.csv", 
     criterion = has_file("MultivariateStatistics_assignment.Rproj")))) {
  rect_constr <- read.csv(
    find_root_file("data/rect_constr.csv", 
                   criterion = 
                     has_file("MultivariateStatistics_assignment.Rproj")))
} else {
  data(rect_constr) 
}
if (file.exists(find_root_file("data/rectangles.csv", 
     criterion = has_file("MultivariateStatistics_assignment.Rproj")))) {
  rectangles <- read.csv(
    find_root_file("data/rectangles.csv", 
                   criterion = 
                     has_file("MultivariateStatistics_assignment.Rproj")))
} else {
  data(rectangles) 
}
```

# Appendix

